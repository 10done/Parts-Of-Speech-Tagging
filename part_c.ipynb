{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(json_file):\n",
    "    \"\"\"Load raw data from JSON file.\"\"\"\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return [\n",
    "        (sentence.split(), tags) \n",
    "        for sentence, tags in data\n",
    "    ]\n",
    "\n",
    "def split_data(sentences, test_ratio=0.2):\n",
    "    \"\"\"Split data into train/test sets.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    indices = np.random.permutation(len(sentences))\n",
    "    split_idx = int(len(sentences) * (1 - test_ratio))\n",
    "    return [sentences[i] for i in indices[:split_idx]], [sentences[i] for i in indices[split_idx:]]\n",
    "\n",
    "def map_to_4tags(tag):\n",
    "    \"\"\"Collapse 36 tags into 4 categories.\"\"\"\n",
    "    if tag.startswith('N'): return 'N'\n",
    "    elif tag.startswith('V'): return 'V'\n",
    "    elif tag.startswith('JJ') or tag.startswith('RB'): return 'A'\n",
    "    else: return 'O'\n",
    "\n",
    "def preprocess_4tag(sentences):\n",
    "    \"\"\"Convert tags in sentences to 4 categories.\"\"\"\n",
    "    return [\n",
    "        ([word.lower() for word in words], [map_to_4tags(tag) for tag in tags])\n",
    "        for (words, tags) in sentences\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mappings(sentences):\n",
    "    \"\"\"Generate tag/word indices from training data.\"\"\"\n",
    "    all_tags, all_words = set(), set()\n",
    "    for words, tags in sentences:\n",
    "        all_tags.update(tags)\n",
    "        all_words.update(words)\n",
    "    tag2idx = {tag: i for i, tag in enumerate(all_tags)}\n",
    "    word2idx = {word: i for i, word in enumerate(all_words)}\n",
    "    idx2tag = {i: tag for tag, i in tag2idx.items()}\n",
    "    return tag2idx, word2idx, idx2tag, all_tags, all_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, tag2idx, word2idx):\n",
    "    \"\"\"Train HMM with numpy matrices (add-1 smoothing).\"\"\"\n",
    "    num_tags = len(tag2idx)\n",
    "    num_words = len(word2idx)\n",
    "    \n",
    "    # Initialize matrices\n",
    "    transition = np.ones((num_tags, num_tags))\n",
    "    initial = np.ones(num_tags)\n",
    "    emission = np.ones((num_tags, num_words))\n",
    "    \n",
    "    for words, tags in train_data:\n",
    "        prev_tag_idx = None\n",
    "        for i, (word, tag) in enumerate(zip(words, tags)):\n",
    "            word_idx = word2idx.get(word.lower(), -1)\n",
    "            tag_idx = tag2idx[tag]\n",
    "            \n",
    "            if i == 0:\n",
    "                initial[tag_idx] += 1\n",
    "            else:\n",
    "                transition[prev_tag_idx, tag_idx] += 1\n",
    "            \n",
    "            if word_idx != -1:\n",
    "                emission[tag_idx, word_idx] += 1\n",
    "            \n",
    "            prev_tag_idx = tag_idx\n",
    "    \n",
    "    # Normalize probabilities\n",
    "    initial = np.log(initial / initial.sum())\n",
    "    transition = np.log(transition / transition.sum(axis=1, keepdims=True))\n",
    "    emission = np.log(emission / emission.sum(axis=1, keepdims=True))\n",
    "    \n",
    "    return initial, transition, emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(sentence_words, initial, transition, emission, tag2idx, word2idx):\n",
    "    \"\"\"Fast Viterbi decoding with numpy.\"\"\"\n",
    "    n = len(sentence_words)\n",
    "    num_tags = len(tag2idx)\n",
    "    \n",
    "    # Precompute word indices\n",
    "    word_indices = [word2idx.get(word.lower(), -1) for word in sentence_words]\n",
    "    \n",
    "    # Initialize DP tables\n",
    "    viterbi = np.zeros((n, num_tags)) + initial\n",
    "    backpointers = np.zeros((n, num_tags), dtype=int)\n",
    "    \n",
    "    # First word\n",
    "    if word_indices[0] != -1:\n",
    "        viterbi[0] += emission[:, word_indices[0]]\n",
    "    \n",
    "    # Iterate\n",
    "    for t in range(1, n):\n",
    "        emit = emission[:, word_indices[t]] if word_indices[t] != -1 else 0\n",
    "        scores = viterbi[t-1][:, None] + transition + emit\n",
    "        viterbi[t] = np.max(scores, axis=0)\n",
    "        backpointers[t] = np.argmax(scores, axis=0)\n",
    "    \n",
    "    # Backtrack\n",
    "    best_path = [np.argmax(viterbi[-1])]\n",
    "    for t in reversed(range(1, n)):\n",
    "        best_path.insert(0, backpointers[t, best_path[0]])\n",
    "    \n",
    "    return best_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "36-Tag Model Probabilities\n",
      "========================================\n",
      "\n",
      "=== Initial Probabilities ===\n",
      "DT: 0.2448\n",
      "NNP: 0.1981\n",
      "IN: 0.1363\n",
      "PRP: 0.0861\n",
      "CC: 0.0536\n",
      "\n",
      "=== Top Transition Probabilities ===\n",
      "From IN:\n",
      "  → DT: 1.3763\n",
      "  → NNP: 1.1591\n",
      "  → NN: 1.1171\n",
      "  → JJ: 1.1039\n",
      "  → CD: 1.0939\n",
      "From UH:\n",
      "  → IN: 1.0500\n",
      "  → PRP: 1.0500\n",
      "  → VBG: 1.0247\n",
      "  → -RRB-: 1.0247\n",
      "  → JJR: 1.0247\n",
      "From VBZ:\n",
      "  → VBN: 1.1858\n",
      "  → DT: 1.1786\n",
      "  → RB: 1.0983\n",
      "  → IN: 1.0970\n",
      "  → NNP: 1.0757\n",
      "\n",
      "=== Top Emission Probabilities ===\n",
      "Tag IN:\n",
      "  - of: 1.0862\n",
      "  - in: 1.0635\n",
      "  - for: 1.0315\n",
      "  - on: 1.0184\n",
      "  - that: 1.0184\n",
      "Tag UH:\n",
      "  - ``no.'': 1.0001\n",
      "  - ``mindful: 1.0001\n",
      "  - Viacom's: 1.0001\n",
      "  - reviewing: 1.0001\n",
      "  - Force: 1.0001\n",
      "Tag VBZ:\n",
      "  - is: 1.0323\n",
      "  - has: 1.0164\n",
      "  - says: 1.0080\n",
      "  - isn't: 1.0022\n",
      "  - says.: 1.0019\n",
      "\n",
      "========================================\n",
      "4-Tag Model Probabilities\n",
      "========================================\n",
      "\n",
      "=== Initial Probabilities ===\n",
      "O: 0.5764\n",
      "N: 0.2957\n",
      "A: 0.0986\n",
      "V: 0.0293\n",
      "\n",
      "=== Top Transition Probabilities ===\n",
      "From N:\n",
      "  → O: 1.5032\n",
      "  → N: 1.4347\n",
      "  → V: 1.1957\n",
      "  → A: 1.0541\n",
      "From O:\n",
      "  → N: 1.4569\n",
      "  → O: 1.3708\n",
      "  → V: 1.1768\n",
      "  → A: 1.1566\n",
      "From V:\n",
      "  → O: 1.7306\n",
      "  → N: 1.1651\n",
      "  → V: 1.1638\n",
      "  → A: 1.1584\n",
      "\n",
      "=== Top Emission Probabilities ===\n",
      "Tag N:\n",
      "  - mr.: 1.0087\n",
      "  - u.s.: 1.0045\n",
      "  - new: 1.0038\n",
      "  - company: 1.0036\n",
      "  - stock: 1.0034\n",
      "Tag O:\n",
      "  - the: 1.1017\n",
      "  - of: 1.0489\n",
      "  - to: 1.0468\n",
      "  - a: 1.0420\n",
      "  - in: 1.0366\n",
      "Tag V:\n",
      "  - is: 1.0219\n",
      "  - said: 1.0177\n",
      "  - was: 1.0121\n",
      "  - be: 1.0119\n",
      "  - are: 1.0115\n"
     ]
    }
   ],
   "source": [
    "def get_top_probabilities(matrix, idx2tag, top_k=5, is_transition=False):\n",
    "    \"\"\"Extract top probabilities from numpy matrix.\"\"\"\n",
    "    results = {}\n",
    "    for i in range(matrix.shape[0]):\n",
    "        tag = idx2tag[i]\n",
    "        probs = matrix[i]\n",
    "        top_indices = np.argsort(probs)[-top_k:][::-1]\n",
    "        results[tag] = [\n",
    "            (idx2tag[j] if is_transition else j, np.exp(probs[j]))  # Fixed parenthesis\n",
    "            for j in top_indices\n",
    "        ]\n",
    "    return results\n",
    "\n",
    "def print_tag_probabilities(initial_probs, transition_probs, emission_probs, \n",
    "                           idx2tag, word2idx, top_k=5):\n",
    "    \"\"\"Print probabilities in readable format.\"\"\"\n",
    "    # Reverse word index for lookup\n",
    "    idx2word = {v: k for k, v in word2idx.items()}\n",
    "    \n",
    "    print(\"\\n=== Initial Probabilities ===\")\n",
    "    initial_exp = np.exp(initial_probs)\n",
    "    for tag_idx in np.argsort(initial_exp)[::-1][:top_k]:\n",
    "        print(f\"{idx2tag[tag_idx]}: {initial_exp[tag_idx]:.4f}\")\n",
    "    \n",
    "    print(\"\\n=== Top Transition Probabilities ===\")\n",
    "    trans_top = get_top_probabilities(np.exp(transition_probs), idx2tag, top_k, True)\n",
    "    for tag, probs in list(trans_top.items())[:3]:  # Print first 3 tags for brevity\n",
    "        print(f\"From {tag}:\")\n",
    "        for target_tag, prob in probs:\n",
    "            print(f\"  → {target_tag}: {prob:.4f}\")\n",
    "    \n",
    "    print(\"\\n=== Top Emission Probabilities ===\")\n",
    "    emit_top = get_top_probabilities(np.exp(emission_probs), idx2tag, top_k)\n",
    "    for tag, probs in list(emit_top.items())[:3]:  # Print first 3 tags\n",
    "        print(f\"Tag {tag}:\")\n",
    "        for word_idx, prob in probs:\n",
    "            word = idx2word.get(word_idx, \"UNK\")\n",
    "            print(f\"  - {word}: {prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 36-tag model...\n",
      "36-Tag Accuracy: 0.7286\n",
      "\n",
      "Training 4-tag model...\n",
      "4-Tag Accuracy: 0.8818\n"
     ]
    }
   ],
   "source": [
    "sentences = load_data(\"penn-data.json\")\n",
    "train_36, test_36 = split_data(sentences)\n",
    "\n",
    "# Preprocess for 4-tag\n",
    "train_4 = preprocess_4tag(train_36)\n",
    "test_4 = preprocess_4tag(test_36)\n",
    "\n",
    "# ------------------- 36-Tag Configuration ------------------- #\n",
    "print(\"Training 36-tag model...\")\n",
    "tag2idx_36, word2idx_36, idx2tag_36, _, _ = create_mappings(train_36)\n",
    "initial_36, trans_36, emit_36 = train_model(train_36, tag2idx_36, word2idx_36)\n",
    "\n",
    "# Predict\n",
    "preds_36 = []\n",
    "for words, _ in test_36:\n",
    "    path = viterbi(words, initial_36, trans_36, emit_36, tag2idx_36, word2idx_36)\n",
    "    preds_36.append([idx2tag_36[idx] for idx in path])\n",
    "\n",
    "# Evaluate\n",
    "correct_36 = sum(1 for (_, tags), pred in zip(test_36, preds_36) for t, p in zip(tags, pred) if t == p)\n",
    "total_36 = sum(len(tags) for (_, tags) in test_36)\n",
    "print(f\"36-Tag Accuracy: {correct_36 / total_36:.4f}\")\n",
    "\n",
    "# ------------------- 4-Tag Configuration ------------------- #\n",
    "print(\"\\nTraining 4-tag model...\")\n",
    "tag2idx_4, word2idx_4, idx2tag_4, _, _ = create_mappings(train_4)\n",
    "initial_4, trans_4, emit_4 = train_model(train_4, tag2idx_4, word2idx_4)\n",
    "\n",
    "# Predict\n",
    "preds_4 = []\n",
    "for words, _ in test_4:\n",
    "    path = viterbi(words, initial_4, trans_4, emit_4, tag2idx_4, word2idx_4)\n",
    "    preds_4.append([idx2tag_4[idx] for idx in path])\n",
    "\n",
    "# Evaluate\n",
    "correct_4 = sum(1 for (_, tags), pred in zip(test_4, preds_4) for t, p in zip(tags, pred) if t == p)\n",
    "total_4 = sum(len(tags) for (_, tags) in test_4)\n",
    "print(f\"4-Tag Accuracy: {correct_4 / total_4:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "36-Tag Model Probabilities\n",
      "========================================\n",
      "\n",
      "=== Initial Probabilities ===\n",
      "DT: 0.2448\n",
      "NNP: 0.1981\n",
      "IN: 0.1363\n",
      "PRP: 0.0861\n",
      "CC: 0.0536\n",
      "\n",
      "=== Top Transition Probabilities ===\n",
      "From IN:\n",
      "  → DT: 1.3763\n",
      "  → NNP: 1.1591\n",
      "  → NN: 1.1171\n",
      "  → JJ: 1.1039\n",
      "  → CD: 1.0939\n",
      "From UH:\n",
      "  → IN: 1.0500\n",
      "  → PRP: 1.0500\n",
      "  → VBG: 1.0247\n",
      "  → -RRB-: 1.0247\n",
      "  → JJR: 1.0247\n",
      "From VBZ:\n",
      "  → VBN: 1.1858\n",
      "  → DT: 1.1786\n",
      "  → RB: 1.0983\n",
      "  → IN: 1.0970\n",
      "  → NNP: 1.0757\n",
      "\n",
      "=== Top Emission Probabilities ===\n",
      "Tag IN:\n",
      "  - of: 1.0862\n",
      "  - in: 1.0635\n",
      "  - for: 1.0315\n",
      "  - on: 1.0184\n",
      "  - that: 1.0184\n",
      "Tag UH:\n",
      "  - ``no.'': 1.0001\n",
      "  - ``mindful: 1.0001\n",
      "  - Viacom's: 1.0001\n",
      "  - reviewing: 1.0001\n",
      "  - Force: 1.0001\n",
      "Tag VBZ:\n",
      "  - is: 1.0323\n",
      "  - has: 1.0164\n",
      "  - says: 1.0080\n",
      "  - isn't: 1.0022\n",
      "  - says.: 1.0019\n",
      "\n",
      "========================================\n",
      "4-Tag Model Probabilities\n",
      "========================================\n",
      "\n",
      "=== Initial Probabilities ===\n",
      "O: 0.5764\n",
      "N: 0.2957\n",
      "A: 0.0986\n",
      "V: 0.0293\n",
      "\n",
      "=== Top Transition Probabilities ===\n",
      "From N:\n",
      "  → O: 1.5032\n",
      "  → N: 1.4347\n",
      "  → V: 1.1957\n",
      "  → A: 1.0541\n",
      "From O:\n",
      "  → N: 1.4569\n",
      "  → O: 1.3708\n",
      "  → V: 1.1768\n",
      "  → A: 1.1566\n",
      "From V:\n",
      "  → O: 1.7306\n",
      "  → N: 1.1651\n",
      "  → V: 1.1638\n",
      "  → A: 1.1584\n",
      "\n",
      "=== Top Emission Probabilities ===\n",
      "Tag N:\n",
      "  - mr.: 1.0087\n",
      "  - u.s.: 1.0045\n",
      "  - new: 1.0038\n",
      "  - company: 1.0036\n",
      "  - stock: 1.0034\n",
      "Tag O:\n",
      "  - the: 1.1017\n",
      "  - of: 1.0489\n",
      "  - to: 1.0468\n",
      "  - a: 1.0420\n",
      "  - in: 1.0366\n",
      "Tag V:\n",
      "  - is: 1.0219\n",
      "  - said: 1.0177\n",
      "  - was: 1.0121\n",
      "  - be: 1.0119\n",
      "  - are: 1.0115\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"36-Tag Model Probabilities\")\n",
    "print(\"=\"*40)\n",
    "print_tag_probabilities(\n",
    "    initial_36, \n",
    "    trans_36, \n",
    "    emit_36, \n",
    "    idx2tag_36, \n",
    "    word2idx_36\n",
    ")\n",
    "\n",
    "# ------------------- 4-Tag Probabilities ------------------- #\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"4-Tag Model Probabilities\")\n",
    "print(\"=\"*40)\n",
    "print_tag_probabilities(\n",
    "    initial_4, \n",
    "    trans_4, \n",
    "    emit_4, \n",
    "    idx2tag_4, \n",
    "    word2idx_4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
